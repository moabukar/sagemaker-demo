{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Deployment and Inference\n",
        "\n",
        "Deploy and test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "from sagemaker.sklearn import SKLearnModel\n",
        "from sagemaker.serializers import CSVSerializer\n",
        "from sagemaker.deserializers import JSONDeserializer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "sess = sagemaker.Session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve variables\n",
        "%store -r best_model_data\n",
        "%store -r test_s3_path\n",
        "%store -r role\n",
        "\n",
        "print(f'Model: {best_model_data}')\n",
        "print(f'Test data: {test_s3_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "sklearn_model = SKLearnModel(\n",
        "    model_data=best_model_data,\n",
        "    role=role,\n",
        "    entry_point='../scripts/inference.py',\n",
        "    framework_version='1.2-1',\n",
        "    py_version='py3'\n",
        ")\n",
        "\n",
        "print('Model object created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deploy endpoint\n",
        "endpoint_name = f'demo-endpoint-{int(time.time())}'\n",
        "\n",
        "predictor = sklearn_model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type='ml.m5.large',\n",
        "    endpoint_name=endpoint_name,\n",
        "    serializer=CSVSerializer(),\n",
        "    deserializer=JSONDeserializer()\n",
        ")\n",
        "\n",
        "print(f'Endpoint deployed: {endpoint_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inference\n",
        "test_df = pd.read_csv(test_s3_path)\n",
        "X_test = test_df.drop('target', axis=1)\n",
        "y_test = test_df['target']\n",
        "\n",
        "sample = X_test.iloc[0].values\n",
        "result = predictor.predict(sample)\n",
        "\n",
        "print(f'Prediction: {result[\"prediction\"]}')\n",
        "print(f'Confidence: {result[\"confidence\"]:.4f}')\n",
        "print(f'Actual: {y_test.iloc[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch predictions\n",
        "n_samples = 10\n",
        "predictions = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    sample = X_test.iloc[i].values\n",
        "    result = predictor.predict(sample)\n",
        "    predictions.append(result['prediction'])\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Actual': y_test.iloc[:n_samples].values,\n",
        "    'Predicted': predictions\n",
        "})\n",
        "comparison['Correct'] = comparison['Actual'] == comparison['Predicted']\n",
        "\n",
        "print(comparison)\n",
        "print(f'Accuracy: {comparison[\"Correct\"].mean():.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Latency test\n",
        "latencies = []\n",
        "n_requests = 50\n",
        "\n",
        "for i in range(n_requests):\n",
        "    sample = X_test.iloc[i % len(X_test)].values\n",
        "    start = time.time()\n",
        "    predictor.predict(sample)\n",
        "    latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "print(f'Mean latency: {np.mean(latencies):.2f}ms')\n",
        "print(f'P95 latency: {np.percentile(latencies, 95):.2f}ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup (uncomment to delete)\n",
        "# predictor.delete_endpoint()\n",
        "# predictor.delete_model()\n",
        "\n",
        "print(f'To delete: aws sagemaker delete-endpoint --endpoint-name {endpoint_name}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
