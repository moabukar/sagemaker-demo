{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration and Preparation\n",
        "\n",
        "This notebook covers:\n",
        "- Generating synthetic dataset\n",
        "- Exploratory data analysis\n",
        "- Feature engineering\n",
        "- Uploading data to S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import boto3\n",
        "import sagemaker\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sess = sagemaker.Session()\n",
        "bucket = sess.default_bucket()\n",
        "role = sagemaker.get_execution_role()\n",
        "region = sess.boto_region_name\n",
        "\n",
        "print(f'SageMaker bucket: {bucket}')\n",
        "print(f'Region: {region}')\n",
        "print(f'Role: {role}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    n_classes=2,\n",
        "    weights=[0.7, 0.3],\n",
        "    flip_y=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "feature_names = [f'feature_{i}' for i in range(20)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(f'Class distribution:\\n{df[\"target\"].value_counts(normalize=True)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "df['target'].value_counts().plot(kind='bar')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature distributions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(feature_names[:6]):\n",
        "    axes[idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[idx].set_title(f'{col} Distribution')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = df[feature_names[:10]].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "df['feature_0_x_1'] = df['feature_0'] * df['feature_1']\n",
        "df['feature_2_squared'] = df['feature_2'] ** 2\n",
        "df['feature_sum'] = df[feature_names[:5]].sum(axis=1)\n",
        "df['feature_mean'] = df[feature_names[:5]].mean(axis=1)\n",
        "\n",
        "print('Added engineered features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
        "\n",
        "print(f'Training set: {train_df.shape}')\n",
        "print(f'Test set: {test_df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload to S3\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\n",
        "prefix = 'classification-demo'\n",
        "train_s3_path = sess.upload_data('train.csv', bucket=bucket, key_prefix=f'{prefix}/data')\n",
        "test_s3_path = sess.upload_data('test.csv', bucket=bucket, key_prefix=f'{prefix}/data')\n",
        "\n",
        "print(f'Training data: {train_s3_path}')\n",
        "print(f'Test data: {test_s3_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save for next notebook\n",
        "%store train_s3_path\n",
        "%store test_s3_path\n",
        "%store bucket\n",
        "%store role"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
